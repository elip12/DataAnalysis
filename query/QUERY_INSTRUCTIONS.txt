INSTRUCTIONS FOR RUNNING QUERYMERGE.PY

Hello and welcome to the querymerge.py tutorial!
This document will teach you how to conduct a query analysis on EEE data using
your terminal or command line.

Quick version: % python3 /data/KLAB/ptt_express_analysis/MergeFunctions/querymerge.py /data/KLAB/EEE_data/Processed/ /data/KLAB/EEE_data/Processed/oTree/EEE_otree_new.csv leeps_id screen1,screen2, var1,var2 mean,std 20

Detailed version:

STEP 1)
Log into the socs-stats server over ssh:
% ssh myid@socs-stats.ucsc.edu
enter your blue password

Install anaconda python on your personal me@socs-stats.ucsc.edu account:
(YOU ONLY NEED TO DO THIS ONE TIME. IF YOU ARE NOT SURE IF YOU ALREADY INSTALLED
ANACONDA, TYPE python3 --version. If you get the message 'python3 not found' or
something of the like, continue reading this. If it says something like '3.4.5'
skip to STEP 2.)

% cd
% wget https://repo.continuum.io/archive/Anaconda3-2.2.0-Linux-x86_64.sh
% sh Anaconda3-2.2.0-Linux-x86_64.sh

Go through the installer process,  including:

Do you wish the installer to prepend the Anaconda3 install location
to PATH in your /home/socsciadmin/.bashrc ? [yes|no]
[no] >>> yes

Then:

% source .bashrc

Verify that it works:

% python3
Python 3.4.3 |Anaconda 2.2.0 (64-bit)| (default, Mar  6 2015, 12:03:53)
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type "help", "copyright", "credits" or "license" for more information.

<Control-D to exit>

Please reference the Conda Cheat Sheet for quick reference:
https://conda.io/docs/using/cheatsheet.html

Lastly:
https://conda.io/docs/test-drive.html

STEP 2)
Update packages and Python version to 3.4.5-0:
% conda update conda

Identify the 8 arguments for the querymerge.py script:
(feel free to copy and paste these when you get to STEP 3)

a)  the path to the script itself -- this should always be:

    /data/KLAB/ptt_express_analysis/MergeFunctions/querymerge.py

b)  the directory containing the Afdx and Leda folders -- this should always be:

    /data/KLAB/EEE_data/Processed/

c)  the path to the oTree CSV file -- this should always be:

    /data/KLAB/EEE_data/Processed/oTree/OTREE_FILENAME.csv

d)  the name of the column in the oTree.csv that holds the LEEPS-IDs:

    something like leeps_id or participant_label

e)  the names of the desired screens, from the oTree.csv -- for example:

    player_time_EmoQuestPage1,player_time_EmoQuestPage1_2

    (You can include as many screens as you want, and they must be separated
     by commas and not spaces.)

f)  the variable names, from the Leda or Afdx files -- for example:

    disgust,analysis.phasicData

    (You can include as many variables as you want, and they must be separated
     by commas and not spaces.)

g)  the functions to apply to the selected data -- for example:

    mean,std,min,max

    (You can include as many fcns as you want, and they must be separated
     by commas and not spaces.
     Only the functions mean, standad deviation, min, and max are supported,
     but you can input mean, np.mean, std, sd, np.std, min, np.min, max, np.max)

h)  the delta seconds, starting at the timestamp corresponding to the selected
    screen. So if delta_ts = 20, the program will get data from when the screen
    appears until 20 seconds after that -- for example:

    20, 5, 1, 6, 30, 60, 120, 3600

STEP 3)
Run the script. This can be done from any folder inside the server.
Separate arguments a-h with spaces and no commas. Make sure everything is typed
correctly: feel free to copy and paste from this document.

% python3 /data/KLAB/ptt_express_analysis/MergeFunctions/querymerge.py /data/KLAB/EEE_data/Processed/ /data/KLAB/EEE_data/Processed/oTree/EEE_otree_new.csv leeps_id screen1,screen2, var1,var2 mean,std 20

The results will be stored in a CSV file called EEE_otree_postquery.csv in
/data/KLAB/EEE_data/Processed/oTree/ which is where the input oTree file
should also be located.
